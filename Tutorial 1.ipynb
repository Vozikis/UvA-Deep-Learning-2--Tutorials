{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "## PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip3 install pytorch-lightning>=1.4 --quiet\n",
    "    import pytorch_lightning as pl\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the folder where the datasets are be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"../../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../../saved_models/DL2/GDL\"\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"mps:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "# Define the path where you want to save the files (adjust this path as needed)\n",
    "CHECKPOINT_PATH = \"/Users/antonis/Documents/Github_Models\"\n",
    "\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/DL2/GDL/\"\n",
    "\n",
    "# Files to download\n",
    "files = [\"paprika.tiff\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            # Use urllib to download files\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupBase(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dimension, identity):\n",
    "        \"\"\" Implements a group.\n",
    "\n",
    "        @param dimension: Dimensionality of the group (number of dimensions in the basis of the algebra).\n",
    "        @param identity: Identity element of the group.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dimension = dimension\n",
    "        self.register_buffer('identity', torch.Tensor(identity))\n",
    "\n",
    "    def elements(self):\n",
    "        \"\"\" Obtain a tensor containing all group elements in this group.\n",
    "        \n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def product(self, h, h_prime):\n",
    "        \"\"\" Defines group product on two group elements.\n",
    "\n",
    "        @param h: Group element 1\n",
    "        @param h_prime: Group element 2\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def inverse(self, h):\n",
    "        \"\"\" Defines inverse for group element.\n",
    "\n",
    "        @param h: A group element from subgroup H.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def left_action_on_R2(self, h, x):\n",
    "        \"\"\" Group action of an element from the subgroup H on a vector in R2.\n",
    "\n",
    "        @param h: A group element from subgroup H.\n",
    "        @param x: Vectors in R2.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def matrix_representation(self, h):\n",
    "        \"\"\" Obtain a matrix representation in R^2 for an element h.\n",
    "\n",
    "        @param h: Group element\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def determinant(self, h):\n",
    "        \"\"\" Calculate the determinant of the representation of a group element\n",
    "        h.\n",
    "\n",
    "        @param g:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def normalize_group_parameterization(self, h):\n",
    "        \"\"\" Map the group elements to an interval [-1, 1]. We use this to create\n",
    "        a standardized input for obtaining weights over the group.\n",
    "\n",
    "        @param g:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicGroup(GroupBase):\n",
    "\n",
    "    def __init__(self, order):\n",
    "        super().__init__(\n",
    "            dimension=1,\n",
    "            identity=[0.]\n",
    "        )\n",
    "\n",
    "        assert order > 1\n",
    "        self.order = torch.tensor(order)\n",
    "\n",
    "    def elements(self):\n",
    "        \"\"\" Obtain a tensor containing all group elements in this group.\n",
    "        \n",
    "        @returns elements: Tensor containing group elements of shape [self.order]\n",
    "        \"\"\"\n",
    "        return torch.linspace(\n",
    "            start=0,\n",
    "            end=2 * np.pi * float(self.order - 1) / float(self.order),\n",
    "            steps=self.order,\n",
    "            device=self.identity.device\n",
    "        )\n",
    "    \n",
    "    def product(self, h, h_prime):\n",
    "        \"\"\" Defines group product on two group elements of the cyclic group C4.\n",
    "\n",
    "        @param h: Group element 1\n",
    "        @param h_prime: Group element 2\n",
    "        \n",
    "        @returns product: Tensor containing h \\cdot h_prime with \\cdot the group action.\n",
    "        \"\"\"\n",
    "        # As we directly parameterize the group by its rotation angles, this \n",
    "        # will be a simple addition. Don't forget the closure property though!\n",
    "\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        product = torch.remainder(h + h_prime, 2 * np.pi)\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        return product\n",
    "\n",
    "    def inverse(self, h):\n",
    "        \"\"\" Defines group inverse for an element of the cyclic group C4.\n",
    "\n",
    "        @param h: Group element\n",
    "        \n",
    "        @returns inverse: Tensor containing h^{-1}.\n",
    "        \"\"\"\n",
    "        # Implement the inverse operation. Keep the closure property in mind!\n",
    "\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        inverse = torch.remainder(-h, 2 * np.pi)\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        return inverse\n",
    "    \n",
    "    def left_action_on_R2(self, h, x):\n",
    "        \"\"\" Group action of an element from the subgroup H on a vector in R2.\n",
    "\n",
    "        @param h: A group element from subgroup H.\n",
    "        @param x: Vectors in R2.\n",
    "        \n",
    "        @returns transformed_x: Tensor containing \\rho(h)x.\n",
    "        \"\"\"\n",
    "        # Transform the vector x with h, recall that we are working with a left-regular representation, \n",
    "        # meaning we transform vectors in R^2 through left-matrix multiplication.\n",
    "        transformed_x = torch.tensordot(self.matrix_representation(h), x, dims=1)       \n",
    "        return transformed_x\n",
    "\n",
    "    def matrix_representation(self, h):\n",
    "        \"\"\" Obtain a matrix representation in R^2 for an element h.\n",
    "\n",
    "        @param h: A group element.\n",
    "        \n",
    "        @returns representation: Tensor containing matrix representation of h, shape [2, 2].\n",
    "        \"\"\"\n",
    "        ## YOUR CODE STARTS HERE ##\n",
    "        cos_t = torch.cos(h)\n",
    "        sin_t = torch.sin(h)\n",
    "\n",
    "        representation = torch.tensor([\n",
    "            [cos_t, -sin_t],\n",
    "            [sin_t, cos_t]\n",
    "        ], device=self.identity.device)\n",
    "        ## AND ENDS HERE ##\n",
    "\n",
    "        return representation\n",
    "    \n",
    "    def normalize_group_elements(self, h):\n",
    "        \"\"\" Normalize values of group elements to range between -1 and 1.\n",
    "        The group elements range from 0 to 2pi * (self.order - 1) / self.order,\n",
    "        so we normalize accordingly.\n",
    "\n",
    "        @param h: A group element.\n",
    "        @return normalized_h: Tensor containing normalized value corresponding to element h.\n",
    "        \"\"\"\n",
    "        largest_elem = 2 * np.pi * (self.order - 1) / self.order\n",
    "        normalized_h = (2*h / largest_elem) - 1.\n",
    "        return normalized_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests to verify our implementation.\n",
    "c4 = CyclicGroup(order=4)\n",
    "e, g1, g2, g3 = c4.elements()\n",
    "\n",
    "assert c4.product(e, g1) == g1 and c4.product(g1, g2) == g3\n",
    "assert c4.product(g1, c4.inverse(g1)) == e\n",
    "\n",
    "assert torch.allclose(c4.matrix_representation(e), torch.eye(2))\n",
    "assert torch.allclose(c4.matrix_representation(g2), torch.tensor([[-1, 0], [0, -1]]).float(), atol=1e-6)\n",
    "\n",
    "assert torch.allclose(c4.left_action_on_R2(g1, torch.tensor([0., 1.])), torch.tensor([-1., 0.]), atol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfl_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
